{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Impact of Artificial Intelligence on Higher Education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Artificial intelligence (AI) is transforming higher education, influencing teaching, learning, and administrative practices. As AI becomes more prevalent in educational settings, there is a growing body of research examining its implications, benefits, and challenges in higher education. This notebook aims to explore this research landscape by conducting a two-part analysis.\n",
    "\n",
    "### Part 1: Bibliometric Analysis\n",
    "In the first phase, we perform a bibliometric analysis using data from SCOPUS, aiming to summarize the state of the research in this field. Specifically, our objectives include:\n",
    "- **Quantifying Publication Trends ->** Determining how research on AI in higher education has grown over recent years.\n",
    "- **Identifying Key Contributors ->** Recognizing influential authors, institutions, and countries that are leading research efforts.\n",
    "- **Research Themes and Collaboration Networks ->** Exploring recurring themes, as well as collaborations and partnerships in the literature.\n",
    "\n",
    "### Part 2: Text Mining Analysis\n",
    "Following the bibliometric analysis, we will apply text mining techniques to the articles themselves. This phase will enable us to delve deeper into the content, uncovering nuanced insights into how AI is being discussed and understood in higher education contexts. In particular, we aim to:\n",
    "- **Extract Key Topics ->** Use natural language processing (NLP) methods to identify key themes and subtopics.\n",
    "- **Analyze Sentiment and Context ->** Examine how AIâ€™s impact is portrayed in higher education, focusing on sentiments around its benefits and challenges.\n",
    "- **Identify Emerging Trends ->** Detect emerging applications or innovative uses of AI in education.\n",
    "\n",
    "### Methodology\n",
    "We will use SCOPUS API to aquire articles based on the following search query:\n",
    "``` \"impact\" AND \"high* education\" AND \"artificial intelligence\" AND PUBYEAR < 2025 ```. Our approach will follow these steps:\n",
    "1. **Data collection ->** Retrieve bibliometric data from SCOPUS, including article titles, abstracts, authors, affiliations, and publication years.\n",
    "2. **Data Processing ->** Organize and clean the data for analysis, ensuring it is suitable for quantitative and qualitative assessments.\n",
    "3. **Bibliometric Analysis:**\n",
    "    * **Publication Trends ->** Analyze the number of publications over time to identify growth patterns.\n",
    "    * **Key Contributors ->** Identify leading authors, institutions, and countries in AI research within higher education.\n",
    "    * **Research Themes ->** Use text mining techniques to uncover major themes and topics in the literature.\n",
    "    * **Collaborative Networks ->** Examine co-authorship and institutional collaborations.\n",
    "4. **Exploring Potential Machine Learning Applications ->** Briefly discuss potential applications of machine learning techniques to further analyze or extend insights from the bibliometric data.\n",
    "\n",
    "### Expected outcomes\n",
    "This analysis will contribute to understanding the broader impact of AI on higher education, offering valuable perspectives for academics, practitioners, and policymakers aiming to leverage AI technologies to enhance educational experiences and outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing required libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "import math \n",
    "import pandas as pd\n",
    "\n",
    "# Add custom module that provides auxiliar functions\n",
    "aux_modules_path = os.path.abspath(os.path.join('./scripts'))\n",
    "if aux_modules_path not in sys.path:\n",
    "    sys.path.append(aux_modules_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API Key Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key: dc7c18eddcd470e03ed6f72cf4a11585\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the API key\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "\n",
    "# Verify if the API key was loaded\n",
    "print(f\"API Key: {API_KEY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Collection\n",
    "This will take some time due to the high amount of articles retrieved. This will retrieve 5000 articles, even though the query results in over 50000 articles, due to SCOPUS API imposing a maximum cap on the number of results retrieved per query of 5000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit the rate limit of results retrieved.\n",
      "Number of articles retrieved:  5000\n",
      "Total number of articles: 50568\n"
     ]
    }
   ],
   "source": [
    "# variable to store the data returned by the SCOPUS API\n",
    "API_DATA = None\n",
    "\n",
    "# query to send to SCOPUS API\n",
    "user_query = '\"impact\" AND \"high* education\" AND \"artificial intelligence\" AND PUBYEAR < 2025'\n",
    "\n",
    "def fetch_all_articles():\n",
    "    articles = []\n",
    "    total_results = None  # total articles queriable with this query\n",
    "    start = 0\n",
    "    count = 25  # results per page, max 25\n",
    "    \n",
    "    while True:\n",
    "        params = {\n",
    "            'query': user_query,\n",
    "            'apiKey': API_KEY,\n",
    "            'start': start,\n",
    "            'count': count\n",
    "        }\n",
    "        \n",
    "        response = requests.get(\"https://api.elsevier.com/content/search/scopus\", params=params)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code != 200:\n",
    "            if response.status_code == 429:\n",
    "                print(\"You have hit the limit quota:\", response.status_code)\n",
    "                break\n",
    "            if len(articles) >= 5000:\n",
    "                print(\"Hit the rate limit of results retrieved.\")\n",
    "                break\n",
    "            print(\"Failed to retrieve data:\", response.status_code)\n",
    "            break\n",
    "        \n",
    "        data = response.json()\n",
    "        entries = data.get(\"search-results\", {}).get(\"entry\", [])\n",
    "        \n",
    "        if total_results == None and 'opensearch:totalResults' in data.get(\"search-results\", {}):\n",
    "            total_results = int(data.get(\"search-results\", {}).get(\"opensearch:totalResults\"))\n",
    "\n",
    "        # If there are no more entries, stop the loop\n",
    "        if not entries:\n",
    "            break\n",
    "        \n",
    "        # Process each entry and add it to the articles list\n",
    "        for entry in entries:\n",
    "            article_data = {\n",
    "                \"title\": entry.get(\"dc:title\", \"No title\"),\n",
    "                \"author_names\": [author.get(\"authname\") for author in entry.get(\"author\", [])],\n",
    "                \"publication_name\": entry.get(\"prism:publicationName\"),\n",
    "                \"publication_date\": entry.get(\"prism:coverDate\"),\n",
    "                \"doi\": entry.get(\"prism:doi\"),\n",
    "                \"cited_by_count\": entry.get(\"citedby-count\", \"0\"),\n",
    "                \"abstract\": entry.get(\"dc:description\", \"No abstract\"),\n",
    "                \"keywords\": [kw.get(\"keyword\") for kw in entry.get(\"keywords\", [])],\n",
    "                \"affiliations\": [\n",
    "                    {\n",
    "                        \"name\": affil.get(\"affilname\", \"No affiliation name\"),\n",
    "                        \"city\": affil.get(\"affiliation-city\", \"No city\"),\n",
    "                        \"country\": affil.get(\"affiliation-country\", \"No country\")\n",
    "                    }\n",
    "                    for affil in entry.get(\"affiliation\", [])\n",
    "                ]\n",
    "            }\n",
    "            articles.append(article_data)\n",
    "        \n",
    "        # Update the start index for the next batch\n",
    "        start += count\n",
    "\n",
    "    print(\"Number of articles retrieved: \", len(articles))\n",
    "    print(f\"Total number of articles: {total_results}\")\n",
    "    return pd.DataFrame(articles)\n",
    "\n",
    "# Fetch all articles and load them into a DataFrame\n",
    "API_DATA = fetch_all_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(API_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Bibliometric analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
